{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractive question answering using Transformers developed by Hugging Face, Inc.\n",
    "# Note: Transformers were installed with 'python -m pip install transformers' in pytorch environment (pytorchenv active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary transformers classes and torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate pretrained tokenizer and model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide text and questions\n",
    "\n",
    "# text from Wikipedea: https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)\n",
    "text = r\"\"\"\n",
    "The Transformer is a deep machine learning model introduced in 2017, used primarily in the field of natural language processing \n",
    "(NLP).[1] Like recurrent neural networks (RNNs), Transformers are designed to handle ordered sequences of data, \n",
    "such as natural language, for various tasks such as machine translation and text summarization. \n",
    "However, unlike RNNs, Transformers do not require that the sequence be processed in order. So, if the data in question is \n",
    "natural language, the Transformer does not need to process the beginning of a sentence before it processes the end. \n",
    "Due to this feature, the Transformer allows for much more parallelization than RNNs during training.[1]\n",
    "\n",
    "Since their introduction, Transformers have become the basic building block of most state-of-the-art architectures in NLP, \n",
    "replacing gated recurrent neural network models such as the long short-term memory (LSTM) in many cases. \n",
    "Since the Transformer architecture facilitates more parallelization during training computations, \n",
    "it has enabled training on much more data than was possible before it was introduced. \n",
    "This led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers) \n",
    "and GPT-2, which have been trained with huge amounts of general language data prior to being released, \n",
    "and can then be fine-tune trained to specific language tasks.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"What is Transformer?\",\n",
    "    \"Whent was Transformer introduced?\",\n",
    "    \"What are Transformers designed for?\",\n",
    "    \"What tasks can Transformer handle?\",\n",
    "    \"What don't Transformers require?\",\n",
    "    \"What have Transformers become?\",\n",
    "    \"What does Transformer architecture facilitate?\",\n",
    "    \"What did Transformer lead to?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Transformer?\n",
      "Answer: a deep machine learning model\n",
      "\n",
      "Question: Whent was Transformer introduced?\n",
      "Answer: 2017\n",
      "\n",
      "Question: What are Transformers designed for?\n",
      "Answer: to handle ordered sequences of data\n",
      "\n",
      "Question: What tasks can Transformer handle?\n",
      "Answer: machine translation and text summarization\n",
      "\n",
      "Question: What don't Transformers require?\n",
      "Answer: the sequence be processed in order\n",
      "\n",
      "Question: What have Transformers become?\n",
      "Answer: the basic building block of most state - of - the - art architectures\n",
      "\n",
      "Question: What does Transformer architecture facilitate?\n",
      "Answer: more parallelization during training computations\n",
      "\n",
      "Question: What did Transformer lead to?\n",
      "Answer: development of pretrained systems\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# answer questions\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(**inputs)\n",
    "\n",
    "    answer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All questions have been answered!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
